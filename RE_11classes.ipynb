{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e5Ua9H5pFWKY",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 1.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "ed704903-2858-4ebe-e818-b4382b71ac54",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521527163003E12,
     "user_tz": -480.0,
     "elapsed": 1624.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalab\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZoIsoA3vFiT6",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 12.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 102.0
    },
    "outputId": "72f4c7c0-399a-45e8-99f3-7ca4a85f0c55",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521527230035E12,
     "user_tz": -480.0,
     "elapsed": 35858.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into './test1'...\n",
      "remote: Counting objects: 62, done.\u001b[K\n",
      "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
      "remote: Total 62 (delta 18), reused 59 (delta 15), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (62/62), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AlwaysSomeone/RE_11classes.git ./test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "3PsZmyUyF8Nd",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "!cp -R test1/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PzoomSPhGCA-",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 1.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 85.0
    },
    "outputId": "578ed018-4cde-4bf9-b7dc-4c68c88dea68",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521527306717E12,
     "user_tz": -480.0,
     "elapsed": 1631.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t       model\t    show_results.py  test_len.py\r\n",
      "datalab        network.py   test1\t     time_test.py\r\n",
      "evaluation.py  origin_data  test_GRU.py      train_GRU.py\r\n",
      "initial.py     out\t    test_initial     train_loss\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IwWS2jR3GEKG",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 2.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 170.0
    },
    "outputId": "0e5d898b-a9a8-4bfd-94c5-5af80ef7ed34",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521527321555E12,
     "user_tz": -480.0,
     "elapsed": 3195.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading word embedding data...\n",
      "reading relation to id\n",
      "reading train data...\n",
      "reading test data ...\n",
      "organizing train data\n",
      "organizing test data\n",
      "reading training data\n",
      "seprating train data\n",
      "seperating test all data\n"
     ]
    }
   ],
   "source": [
    "!python initial.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zzfnylprGHh4",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 10.0
      },
      {
       "item_id": 20.0
      },
      {
       "item_id": 28.0
      },
      {
       "item_id": 36.0
      },
      {
       "item_id": 46.0
      },
      {
       "item_id": 59.0
      },
      {
       "item_id": 72.0
      },
      {
       "item_id": 87.0
      },
      {
       "item_id": 101.0
      },
      {
       "item_id": 118.0
      },
      {
       "item_id": 130.0
      },
      {
       "item_id": 142.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 11461.0
    },
    "outputId": "a33a4dd9-ba6d-4c9f-b8db-b753adcf5c80",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521527740794E12,
     "user_tz": -480.0,
     "elapsed": 222838.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n",
      "  from ._conv import register_converters as _register_converters\n",
      "main函数开始执行2018-03-20T06:31:50.574321\n",
      "reading wordembedding\n",
      "reading training data\n",
      "2018-03-20T06:31:51.157961\n",
      "WARNING:tensorflow:From /content/network.py:132: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "2018-03-20T06:31:57.677821\n",
      "2018-03-20T06:32:26.660702: step 1, softmax_loss 123.184, acc 0.08\n",
      "2018-03-20T06:32:27.000127: step 2, softmax_loss 123.982, acc 0.14\n",
      "2018-03-20T06:32:27.168819: step 3, softmax_loss 120.538, acc 0.2\n",
      "2018-03-20T06:32:27.328435: step 4, softmax_loss 117.167, acc 0.18\n",
      "2018-03-20T06:32:27.486648: step 5, softmax_loss 115.075, acc 0.18\n",
      "2018-03-20T06:32:27.644953: step 6, softmax_loss 118.727, acc 0.22\n",
      "2018-03-20T06:32:27.797229: step 7, softmax_loss 115.824, acc 0.2\n",
      "2018-03-20T06:32:27.952878: step 8, softmax_loss 113.879, acc 0.22\n",
      "2018-03-20T06:32:28.102791: step 9, softmax_loss 121.148, acc 0.14\n",
      "2018-03-20T06:32:28.253814: step 10, softmax_loss 115.774, acc 0.12\n",
      "2018-03-20T06:32:28.398988: step 11, softmax_loss 112.231, acc 0.1\n",
      "2018-03-20T06:32:28.542984: step 12, softmax_loss 108.584, acc 0.32\n",
      "2018-03-20T06:32:28.690816: step 13, softmax_loss 112.65, acc 0.16\n",
      "2018-03-20T06:32:28.833803: step 14, softmax_loss 105.93, acc 0.28\n",
      "2018-03-20T06:32:28.977583: step 15, softmax_loss 111.941, acc 0.14\n",
      "2018-03-20T06:32:29.125490: step 16, softmax_loss 106.485, acc 0.2\n",
      "2018-03-20T06:32:29.272172: step 17, softmax_loss 106.218, acc 0.2\n",
      "2018-03-20T06:32:29.415872: step 18, softmax_loss 108.051, acc 0.24\n",
      "2018-03-20T06:32:29.564050: step 19, softmax_loss 113.176, acc 0.24\n",
      "2018-03-20T06:32:29.713871: step 20, softmax_loss 111.4, acc 0.22\n",
      "2018-03-20T06:32:29.863399: step 21, softmax_loss 103.811, acc 0.38\n",
      "2018-03-20T06:32:30.009569: step 22, softmax_loss 102.589, acc 0.36\n",
      "2018-03-20T06:32:30.156284: step 23, softmax_loss 102.788, acc 0.38\n",
      "2018-03-20T06:32:30.304701: step 24, softmax_loss 99.2268, acc 0.3\n",
      "2018-03-20T06:32:30.449452: step 25, softmax_loss 109.78, acc 0.16\n",
      "2018-03-20T06:32:30.600056: step 26, softmax_loss 103.198, acc 0.28\n",
      "2018-03-20T06:32:30.752989: step 27, softmax_loss 110.923, acc 0.26\n",
      "2018-03-20T06:32:30.898637: step 28, softmax_loss 103.989, acc 0.36\n",
      "2018-03-20T06:32:31.044709: step 29, softmax_loss 102.56, acc 0.34\n",
      "2018-03-20T06:32:31.191198: step 30, softmax_loss 98.0088, acc 0.36\n",
      "2018-03-20T06:32:31.337716: step 31, softmax_loss 93.0691, acc 0.36\n",
      "2018-03-20T06:32:31.478961: step 32, softmax_loss 82.4598, acc 0.52\n",
      "2018-03-20T06:32:31.624969: step 33, softmax_loss 88.973, acc 0.44\n",
      "2018-03-20T06:32:31.775732: step 34, softmax_loss 85.7896, acc 0.46\n",
      "2018-03-20T06:32:31.926525: step 35, softmax_loss 87.7228, acc 0.42\n",
      "2018-03-20T06:32:32.075017: step 36, softmax_loss 116.509, acc 0.24\n",
      "2018-03-20T06:32:32.229122: step 37, softmax_loss 84.733, acc 0.52\n",
      "2018-03-20T06:32:32.374968: step 38, softmax_loss 99.143, acc 0.3\n",
      "2018-03-20T06:32:32.526122: step 39, softmax_loss 102.962, acc 0.38\n",
      "2018-03-20T06:32:32.672023: step 40, softmax_loss 92.7544, acc 0.3\n",
      "2018-03-20T06:32:32.818671: step 41, softmax_loss 83.8199, acc 0.52\n",
      "2018-03-20T06:32:32.961266: step 42, softmax_loss 94.3942, acc 0.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-20T06:32:33.108246: step 43, softmax_loss 81.5676, acc 0.56\n",
      "2018-03-20T06:32:33.251077: step 44, softmax_loss 91.0229, acc 0.4\n",
      "2018-03-20T06:32:33.397676: step 45, softmax_loss 93.6642, acc 0.4\n",
      "2018-03-20T06:32:33.545348: step 46, softmax_loss 80.429, acc 0.48\n",
      "2018-03-20T06:32:33.690888: step 47, softmax_loss 89.1698, acc 0.48\n",
      "2018-03-20T06:32:33.840265: step 48, softmax_loss 83.5351, acc 0.58\n",
      "2018-03-20T06:32:33.989690: step 49, softmax_loss 80.0789, acc 0.46\n",
      "2018-03-20T06:32:34.134325: step 50, softmax_loss 75.9486, acc 0.54\n",
      "2018-03-20T06:32:34.278731: step 51, softmax_loss 86.7752, acc 0.4\n",
      "2018-03-20T06:32:34.427304: step 52, softmax_loss 80.4125, acc 0.48\n",
      "2018-03-20T06:32:34.577257: step 53, softmax_loss 85.5527, acc 0.5\n",
      "2018-03-20T06:32:34.734445: step 54, softmax_loss 83.7891, acc 0.4\n",
      "2018-03-20T06:32:34.884143: step 55, softmax_loss 84.8486, acc 0.46\n",
      "2018-03-20T06:32:35.034108: step 56, softmax_loss 74.3465, acc 0.56\n",
      "2018-03-20T06:32:35.193349: step 57, softmax_loss 83.5697, acc 0.44\n",
      "2018-03-20T06:32:35.342221: step 58, softmax_loss 72.3134, acc 0.56\n",
      "2018-03-20T06:32:35.492479: step 59, softmax_loss 79.0454, acc 0.44\n",
      "2018-03-20T06:32:35.643427: step 60, softmax_loss 80.317, acc 0.48\n",
      "2018-03-20T06:32:35.794526: step 61, softmax_loss 81.24, acc 0.5\n",
      "2018-03-20T06:32:35.949066: step 62, softmax_loss 83.7987, acc 0.52\n",
      "2018-03-20T06:32:36.100440: step 63, softmax_loss 71.5067, acc 0.48\n",
      "2018-03-20T06:32:36.245608: step 64, softmax_loss 74.7912, acc 0.64\n",
      "2018-03-20T06:32:36.395420: step 65, softmax_loss 59.1407, acc 0.6\n",
      "2018-03-20T06:32:36.548113: step 66, softmax_loss 73.3183, acc 0.44\n",
      "2018-03-20T06:32:36.699024: step 67, softmax_loss 75.5936, acc 0.52\n",
      "2018-03-20T06:32:36.846078: step 68, softmax_loss 79.8542, acc 0.48\n",
      "2018-03-20T06:32:37.004889: step 69, softmax_loss 97.915, acc 0.42\n",
      "2018-03-20T06:32:37.154434: step 70, softmax_loss 62.0948, acc 0.66\n",
      "2018-03-20T06:32:37.302705: step 71, softmax_loss 71.11, acc 0.5\n",
      "2018-03-20T06:32:37.457000: step 72, softmax_loss 52.6246, acc 0.72\n",
      "2018-03-20T06:32:37.607404: step 73, softmax_loss 70.3897, acc 0.6\n",
      "2018-03-20T06:32:37.756101: step 74, softmax_loss 60.0075, acc 0.68\n",
      "2018-03-20T06:32:37.905895: step 75, softmax_loss 74.9131, acc 0.52\n",
      "2018-03-20T06:32:38.051964: step 76, softmax_loss 78.4693, acc 0.54\n",
      "2018-03-20T06:32:38.203115: step 77, softmax_loss 74.6955, acc 0.48\n",
      "2018-03-20T06:32:38.345671: step 78, softmax_loss 61.5462, acc 0.54\n",
      "2018-03-20T06:32:38.492638: step 79, softmax_loss 61.3294, acc 0.66\n",
      "2018-03-20T06:32:38.642331: step 80, softmax_loss 64.4463, acc 0.6\n",
      "2018-03-20T06:32:38.789748: step 81, softmax_loss 54.591, acc 0.76\n",
      "2018-03-20T06:32:38.936842: step 82, softmax_loss 76.4618, acc 0.46\n",
      "2018-03-20T06:32:39.083238: step 83, softmax_loss 75.2392, acc 0.52\n",
      "2018-03-20T06:32:39.229105: step 84, softmax_loss 77.7563, acc 0.44\n",
      "2018-03-20T06:32:39.376639: step 85, softmax_loss 65.4518, acc 0.56\n",
      "2018-03-20T06:32:39.521498: step 86, softmax_loss 67.1635, acc 0.62\n",
      "2018-03-20T06:32:39.672902: step 87, softmax_loss 74.3759, acc 0.44\n",
      "2018-03-20T06:32:39.821106: step 88, softmax_loss 64.28, acc 0.56\n",
      "2018-03-20T06:32:39.971812: step 89, softmax_loss 68.3958, acc 0.5\n",
      "2018-03-20T06:32:40.121069: step 90, softmax_loss 66.8217, acc 0.54\n",
      "2018-03-20T06:32:40.267656: step 91, softmax_loss 69.5755, acc 0.58\n",
      "2018-03-20T06:32:40.413907: step 92, softmax_loss 58.5775, acc 0.66\n",
      "2018-03-20T06:32:40.560879: step 93, softmax_loss 51.0184, acc 0.66\n",
      "2018-03-20T06:32:40.713106: step 94, softmax_loss 55.7691, acc 0.64\n",
      "2018-03-20T06:32:40.857454: step 95, softmax_loss 51.3716, acc 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-20T06:32:41.006819: step 96, softmax_loss 68.405, acc 0.58\n",
      "2018-03-20T06:32:41.155106: step 97, softmax_loss 69.9258, acc 0.56\n",
      "2018-03-20T06:32:41.300980: step 98, softmax_loss 50.3441, acc 0.7\n",
      "2018-03-20T06:32:41.446826: step 99, softmax_loss 59.5995, acc 0.62\n",
      "2018-03-20T06:32:41.602255: step 100, softmax_loss 55.6198, acc 0.64\n",
      "2018-03-20T06:32:41.748448: step 101, softmax_loss 56.4449, acc 0.66\n",
      "2018-03-20T06:32:41.895630: step 102, softmax_loss 66.8174, acc 0.52\n",
      "2018-03-20T06:32:42.044467: step 103, softmax_loss 66.54, acc 0.54\n",
      "2018-03-20T06:32:42.183019: step 104, softmax_loss 57.6728, acc 0.66\n",
      "2018-03-20T06:32:42.325977: step 105, softmax_loss 67.0577, acc 0.56\n",
      "2018-03-20T06:32:42.476784: step 106, softmax_loss 51.2697, acc 0.72\n",
      "2018-03-20T06:32:42.621807: step 107, softmax_loss 54.0432, acc 0.66\n",
      "2018-03-20T06:32:42.782421: step 108, softmax_loss 55.0322, acc 0.62\n",
      "2018-03-20T06:32:42.927237: step 109, softmax_loss 58.6558, acc 0.66\n",
      "2018-03-20T06:32:43.070819: step 110, softmax_loss 46.6161, acc 0.8\n",
      "2018-03-20T06:32:43.214394: step 111, softmax_loss 70.0233, acc 0.58\n",
      "2018-03-20T06:32:43.358001: step 112, softmax_loss 73.5279, acc 0.46\n",
      "2018-03-20T06:32:43.506798: step 113, softmax_loss 59.8034, acc 0.7\n",
      "2018-03-20T06:32:43.652070: step 114, softmax_loss 68.3235, acc 0.54\n",
      "2018-03-20T06:32:43.796807: step 115, softmax_loss 55.623, acc 0.56\n",
      "2018-03-20T06:32:43.949210: step 116, softmax_loss 57.1161, acc 0.68\n",
      "2018-03-20T06:32:44.095356: step 117, softmax_loss 57.7375, acc 0.62\n",
      "2018-03-20T06:32:44.241871: step 118, softmax_loss 49.5918, acc 0.7\n",
      "2018-03-20T06:32:44.391405: step 119, softmax_loss 52.8312, acc 0.72\n",
      "2018-03-20T06:32:44.537590: step 120, softmax_loss 65.8401, acc 0.62\n",
      "2018-03-20T06:32:44.687508: step 121, softmax_loss 66.4117, acc 0.58\n",
      "2018-03-20T06:32:44.835066: step 122, softmax_loss 49.0836, acc 0.68\n",
      "2018-03-20T06:32:44.980721: step 123, softmax_loss 63.3441, acc 0.56\n",
      "2018-03-20T06:32:45.127516: step 124, softmax_loss 58.064, acc 0.64\n",
      "2018-03-20T06:32:45.272261: step 125, softmax_loss 54.421, acc 0.66\n",
      "2018-03-20T06:32:45.418230: step 126, softmax_loss 55.4466, acc 0.62\n",
      "2018-03-20T06:32:45.563361: step 127, softmax_loss 53.7804, acc 0.72\n",
      "2018-03-20T06:32:45.704008: step 128, softmax_loss 56.5392, acc 0.64\n",
      "2018-03-20T06:32:45.851745: step 129, softmax_loss 49.7075, acc 0.68\n",
      "2018-03-20T06:32:45.990440: step 130, softmax_loss 58.1705, acc 0.66\n",
      "2018-03-20T06:32:46.137368: step 131, softmax_loss 53.86, acc 0.66\n",
      "2018-03-20T06:32:46.288012: step 132, softmax_loss 52.4994, acc 0.7\n",
      "2018-03-20T06:32:46.435235: step 133, softmax_loss 40.4026, acc 0.74\n",
      "2018-03-20T06:32:46.582066: step 134, softmax_loss 55.189, acc 0.66\n",
      "2018-03-20T06:32:46.728464: step 135, softmax_loss 48.8897, acc 0.74\n",
      "2018-03-20T06:32:46.868273: step 136, softmax_loss 50.443, acc 0.72\n",
      "2018-03-20T06:32:47.011375: step 137, softmax_loss 45.6622, acc 0.76\n",
      "2018-03-20T06:32:47.155966: step 138, softmax_loss 44.7641, acc 0.8\n",
      "2018-03-20T06:32:47.307687: step 139, softmax_loss 51.6192, acc 0.62\n",
      "2018-03-20T06:32:47.463382: step 140, softmax_loss 57.656, acc 0.62\n",
      "2018-03-20T06:32:47.611298: step 141, softmax_loss 48.7443, acc 0.72\n",
      "2018-03-20T06:32:47.760050: step 142, softmax_loss 42.4971, acc 0.72\n",
      "2018-03-20T06:32:47.931549: step 143, softmax_loss 63.0646, acc 0.66\n",
      "2018-03-20T06:32:48.103047: step 144, softmax_loss 55.2983, acc 0.68\n",
      "2018-03-20T06:32:48.252016: step 145, softmax_loss 41.2417, acc 0.68\n",
      "2018-03-20T06:32:48.400543: step 146, softmax_loss 52.4488, acc 0.7\n",
      "2018-03-20T06:32:48.565052: step 147, softmax_loss 39.2743, acc 0.82\n",
      "2018-03-20T06:32:48.714734: step 148, softmax_loss 52.2476, acc 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-20T06:32:48.859677: step 149, softmax_loss 60.46, acc 0.58\n",
      "2018-03-20T06:32:49.006202: step 150, softmax_loss 52.2414, acc 0.66\n",
      "2018-03-20T06:32:49.152448: step 151, softmax_loss 51.0892, acc 0.7\n",
      "2018-03-20T06:32:49.302579: step 152, softmax_loss 40.1518, acc 0.74\n",
      "2018-03-20T06:32:49.448526: step 153, softmax_loss 38.3554, acc 0.74\n",
      "2018-03-20T06:32:49.597350: step 154, softmax_loss 39.3385, acc 0.78\n",
      "2018-03-20T06:32:49.748299: step 155, softmax_loss 45.6694, acc 0.7\n",
      "2018-03-20T06:32:49.894082: step 156, softmax_loss 49.7376, acc 0.72\n",
      "2018-03-20T06:32:50.031790: step 157, softmax_loss 55.1842, acc 0.62\n",
      "2018-03-20T06:32:50.178291: step 158, softmax_loss 32.7378, acc 0.8\n",
      "2018-03-20T06:32:50.321971: step 159, softmax_loss 43.8515, acc 0.78\n",
      "2018-03-20T06:32:50.468991: step 160, softmax_loss 54.9133, acc 0.62\n",
      "2018-03-20T06:32:50.613575: step 161, softmax_loss 44.4493, acc 0.72\n",
      "2018-03-20T06:32:50.758419: step 162, softmax_loss 44.8814, acc 0.74\n",
      "2018-03-20T06:32:50.905023: step 163, softmax_loss 41.1092, acc 0.76\n",
      "2018-03-20T06:32:51.045383: step 164, softmax_loss 41.7052, acc 0.7\n",
      "2018-03-20T06:32:51.188505: step 165, softmax_loss 48.5335, acc 0.76\n",
      "2018-03-20T06:32:51.333655: step 166, softmax_loss 53.6024, acc 0.68\n",
      "2018-03-20T06:32:51.475051: step 167, softmax_loss 50.5953, acc 0.66\n",
      "2018-03-20T06:32:51.622302: step 168, softmax_loss 30.4332, acc 0.84\n",
      "2018-03-20T06:32:51.776233: step 169, softmax_loss 33.6426, acc 0.78\n",
      "2018-03-20T06:32:51.924335: step 170, softmax_loss 44.013, acc 0.74\n",
      "2018-03-20T06:32:52.068519: step 171, softmax_loss 48.0604, acc 0.64\n",
      "2018-03-20T06:32:52.210214: step 172, softmax_loss 38.0036, acc 0.76\n",
      "2018-03-20T06:32:52.355655: step 173, softmax_loss 37.5355, acc 0.78\n",
      "2018-03-20T06:32:52.505390: step 174, softmax_loss 44.1133, acc 0.74\n",
      "2018-03-20T06:32:52.651481: step 175, softmax_loss 45.3622, acc 0.72\n",
      "2018-03-20T06:32:52.793032: step 176, softmax_loss 32.6094, acc 0.8\n",
      "2018-03-20T06:32:52.944110: step 177, softmax_loss 52.0102, acc 0.64\n",
      "2018-03-20T06:32:53.087044: step 178, softmax_loss 36.1387, acc 0.86\n",
      "2018-03-20T06:32:53.244973: step 179, softmax_loss 41.6758, acc 0.8\n",
      "2018-03-20T06:32:53.391598: step 180, softmax_loss 38.593, acc 0.76\n",
      "2018-03-20T06:32:53.533476: step 181, softmax_loss 35.6688, acc 0.82\n",
      "2018-03-20T06:32:53.676474: step 182, softmax_loss 37.1142, acc 0.76\n",
      "2018-03-20T06:32:53.816936: step 183, softmax_loss 49.983, acc 0.72\n",
      "2018-03-20T06:32:53.963544: step 184, softmax_loss 42.3627, acc 0.66\n",
      "2018-03-20T06:32:54.112033: step 185, softmax_loss 49.8838, acc 0.66\n",
      "2018-03-20T06:32:54.257535: step 186, softmax_loss 36.5534, acc 0.74\n",
      "2018-03-20T06:32:54.404850: step 187, softmax_loss 28.0429, acc 0.84\n",
      "2018-03-20T06:32:54.552524: step 188, softmax_loss 42.4499, acc 0.74\n",
      "2018-03-20T06:32:54.702559: step 189, softmax_loss 38.6115, acc 0.8\n",
      "2018-03-20T06:32:54.848711: step 190, softmax_loss 43.8985, acc 0.72\n",
      "2018-03-20T06:32:54.992706: step 191, softmax_loss 43.8983, acc 0.78\n",
      "2018-03-20T06:32:55.135582: step 192, softmax_loss 40.9954, acc 0.74\n",
      "2018-03-20T06:32:55.281626: step 193, softmax_loss 39.5698, acc 0.78\n",
      "2018-03-20T06:32:55.424806: step 194, softmax_loss 38.7101, acc 0.72\n",
      "2018-03-20T06:32:55.571797: step 195, softmax_loss 44.6214, acc 0.76\n",
      "2018-03-20T06:32:55.718631: step 196, softmax_loss 34.4408, acc 0.78\n",
      "2018-03-20T06:32:55.864750: step 197, softmax_loss 37.6396, acc 0.82\n",
      "2018-03-20T06:32:56.009988: step 198, softmax_loss 39.6045, acc 0.78\n",
      "2018-03-20T06:32:56.156432: step 199, softmax_loss 46.9914, acc 0.66\n",
      "2018-03-20T06:32:56.304563: step 200, softmax_loss 49.2441, acc 0.64\n",
      "2018-03-20T06:32:56.453533: step 201, softmax_loss 37.1686, acc 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-20T06:32:56.598618: step 202, softmax_loss 32.5456, acc 0.84\n",
      "2018-03-20T06:32:56.740145: step 203, softmax_loss 29.1729, acc 0.76\n",
      "2018-03-20T06:32:56.886599: step 204, softmax_loss 33.8289, acc 0.8\n",
      "2018-03-20T06:32:57.033072: step 205, softmax_loss 27.5675, acc 0.9\n",
      "2018-03-20T06:32:57.178447: step 206, softmax_loss 38.8984, acc 0.74\n",
      "2018-03-20T06:32:57.327920: step 207, softmax_loss 31.7945, acc 0.84\n",
      "2018-03-20T06:32:57.474551: step 208, softmax_loss 45.0549, acc 0.68\n",
      "2018-03-20T06:32:57.624250: step 209, softmax_loss 35.3049, acc 0.78\n",
      "2018-03-20T06:32:57.768732: step 210, softmax_loss 40.2448, acc 0.8\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-210\n",
      "2018-03-20T06:32:59.996119: step 211, softmax_loss 40.4304, acc 0.8\n",
      "2018-03-20T06:33:00.141123: step 212, softmax_loss 46.148, acc 0.66\n",
      "2018-03-20T06:33:00.286346: step 213, softmax_loss 33.8817, acc 0.78\n",
      "2018-03-20T06:33:00.434241: step 214, softmax_loss 18.9438, acc 0.88\n",
      "2018-03-20T06:33:00.580854: step 215, softmax_loss 33.7752, acc 0.78\n",
      "2018-03-20T06:33:00.724737: step 216, softmax_loss 38.3704, acc 0.74\n",
      "2018-03-20T06:33:00.870671: step 217, softmax_loss 33.7348, acc 0.76\n",
      "2018-03-20T06:33:01.014221: step 218, softmax_loss 40.6575, acc 0.72\n",
      "2018-03-20T06:33:01.156655: step 219, softmax_loss 40.2761, acc 0.74\n",
      "2018-03-20T06:33:01.301395: step 220, softmax_loss 42.9198, acc 0.8\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-220\n",
      "2018-03-20T06:33:03.553045: step 221, softmax_loss 36.3841, acc 0.8\n",
      "2018-03-20T06:33:03.718606: step 222, softmax_loss 38.2959, acc 0.76\n",
      "2018-03-20T06:33:03.861808: step 223, softmax_loss 40.2243, acc 0.72\n",
      "2018-03-20T06:33:04.005321: step 224, softmax_loss 43.0093, acc 0.76\n",
      "2018-03-20T06:33:04.146425: step 225, softmax_loss 29.1167, acc 0.86\n",
      "2018-03-20T06:33:04.291565: step 226, softmax_loss 23.8206, acc 0.9\n",
      "2018-03-20T06:33:04.433744: step 227, softmax_loss 29.2196, acc 0.8\n",
      "2018-03-20T06:33:04.578128: step 228, softmax_loss 51.3422, acc 0.64\n",
      "2018-03-20T06:33:04.721831: step 229, softmax_loss 43.7959, acc 0.68\n",
      "2018-03-20T06:33:04.869151: step 230, softmax_loss 38.7356, acc 0.78\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-230\n",
      "2018-03-20T06:33:06.873616: step 231, softmax_loss 43.3303, acc 0.72\n",
      "2018-03-20T06:33:07.019218: step 232, softmax_loss 44.1466, acc 0.72\n",
      "2018-03-20T06:33:07.162663: step 233, softmax_loss 43.1597, acc 0.68\n",
      "2018-03-20T06:33:07.302538: step 234, softmax_loss 34.5962, acc 0.8\n",
      "2018-03-20T06:33:07.443757: step 235, softmax_loss 43.2749, acc 0.74\n",
      "2018-03-20T06:33:07.588491: step 236, softmax_loss 25.2708, acc 0.86\n",
      "2018-03-20T06:33:07.738788: step 237, softmax_loss 35.0459, acc 0.76\n",
      "2018-03-20T06:33:07.882844: step 238, softmax_loss 25.9846, acc 0.84\n",
      "2018-03-20T06:33:08.026682: step 239, softmax_loss 27.6129, acc 0.84\n",
      "2018-03-20T06:33:08.173298: step 240, softmax_loss 34.1253, acc 0.8\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-240\n",
      "2018-03-20T06:33:10.198079: step 241, softmax_loss 28.1953, acc 0.84\n",
      "2018-03-20T06:33:10.339436: step 242, softmax_loss 35.3653, acc 0.78\n",
      "2018-03-20T06:33:10.483533: step 243, softmax_loss 23.0196, acc 0.88\n",
      "2018-03-20T06:33:10.630364: step 244, softmax_loss 26.1128, acc 0.9\n",
      "2018-03-20T06:33:10.772815: step 245, softmax_loss 30.1066, acc 0.82\n",
      "2018-03-20T06:33:10.918408: step 246, softmax_loss 23.5371, acc 0.84\n",
      "2018-03-20T06:33:11.064649: step 247, softmax_loss 31.9553, acc 0.8\n",
      "2018-03-20T06:33:11.212415: step 248, softmax_loss 24.1843, acc 0.86\n",
      "2018-03-20T06:33:11.353797: step 249, softmax_loss 39.8717, acc 0.7\n",
      "2018-03-20T06:33:11.498673: step 250, softmax_loss 31.7642, acc 0.84\n",
      "saving model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have saved model to ./model/ATT_GRU_model-250\n",
      "2018-03-20T06:33:13.522053: step 251, softmax_loss 47.0048, acc 0.68\n",
      "2018-03-20T06:33:13.669045: step 252, softmax_loss 42.996, acc 0.7\n",
      "2018-03-20T06:33:13.814911: step 253, softmax_loss 27.9562, acc 0.84\n",
      "2018-03-20T06:33:13.959907: step 254, softmax_loss 28.2167, acc 0.9\n",
      "2018-03-20T06:33:14.101893: step 255, softmax_loss 30.3325, acc 0.78\n",
      "2018-03-20T06:33:14.261704: step 256, softmax_loss 29.2354, acc 0.84\n",
      "2018-03-20T06:33:14.408557: step 257, softmax_loss 23.7496, acc 0.88\n",
      "2018-03-20T06:33:14.555635: step 258, softmax_loss 35.8624, acc 0.82\n",
      "2018-03-20T06:33:14.699354: step 259, softmax_loss 28.7681, acc 0.84\n",
      "2018-03-20T06:33:14.846213: step 260, softmax_loss 41.4894, acc 0.68\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-260\n",
      "2018-03-20T06:33:16.864150: step 261, softmax_loss 35.6131, acc 0.82\n",
      "2018-03-20T06:33:17.009127: step 262, softmax_loss 22.576, acc 0.86\n",
      "2018-03-20T06:33:17.148376: step 263, softmax_loss 33.1424, acc 0.78\n",
      "2018-03-20T06:33:17.294803: step 264, softmax_loss 34.0662, acc 0.76\n",
      "2018-03-20T06:33:17.444609: step 265, softmax_loss 35.4572, acc 0.76\n",
      "2018-03-20T06:33:17.601527: step 266, softmax_loss 31.7194, acc 0.72\n",
      "2018-03-20T06:33:17.741172: step 267, softmax_loss 20.0653, acc 0.88\n",
      "2018-03-20T06:33:17.885425: step 268, softmax_loss 30.7134, acc 0.84\n",
      "2018-03-20T06:33:18.033446: step 269, softmax_loss 28.3969, acc 0.86\n",
      "2018-03-20T06:33:18.180774: step 270, softmax_loss 21.6053, acc 0.9\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-270\n",
      "2018-03-20T06:33:20.209602: step 271, softmax_loss 17.769, acc 0.9\n",
      "2018-03-20T06:33:20.355769: step 272, softmax_loss 28.3091, acc 0.84\n",
      "2018-03-20T06:33:20.498732: step 273, softmax_loss 24.979, acc 0.86\n",
      "2018-03-20T06:33:20.645406: step 274, softmax_loss 32.913, acc 0.82\n",
      "2018-03-20T06:33:20.786721: step 275, softmax_loss 23.0236, acc 0.88\n",
      "2018-03-20T06:33:20.938418: step 276, softmax_loss 30.0619, acc 0.78\n",
      "2018-03-20T06:33:21.084551: step 277, softmax_loss 23.2347, acc 0.88\n",
      "2018-03-20T06:33:21.231262: step 278, softmax_loss 26.5963, acc 0.82\n",
      "2018-03-20T06:33:21.374815: step 279, softmax_loss 30.2946, acc 0.76\n",
      "2018-03-20T06:33:21.521711: step 280, softmax_loss 32.3354, acc 0.88\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-280\n",
      "2018-03-20T06:33:23.551735: step 281, softmax_loss 18.4887, acc 0.9\n",
      "2018-03-20T06:33:23.696516: step 282, softmax_loss 22.5374, acc 0.9\n",
      "2018-03-20T06:33:23.838502: step 283, softmax_loss 30.0829, acc 0.8\n",
      "2018-03-20T06:33:23.982608: step 284, softmax_loss 36.964, acc 0.72\n",
      "2018-03-20T06:33:24.127073: step 285, softmax_loss 32.7193, acc 0.8\n",
      "2018-03-20T06:33:24.271760: step 286, softmax_loss 25.7712, acc 0.82\n",
      "2018-03-20T06:33:24.416385: step 287, softmax_loss 27.2416, acc 0.82\n",
      "2018-03-20T06:33:24.560010: step 288, softmax_loss 21.6818, acc 0.9\n",
      "2018-03-20T06:33:24.719991: step 289, softmax_loss 27.8114, acc 0.84\n",
      "2018-03-20T06:33:24.866534: step 290, softmax_loss 29.3531, acc 0.86\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-290\n",
      "2018-03-20T06:33:26.862095: step 291, softmax_loss 28.1426, acc 0.78\n",
      "2018-03-20T06:33:27.008151: step 292, softmax_loss 26.4744, acc 0.82\n",
      "2018-03-20T06:33:27.151304: step 293, softmax_loss 24.793, acc 0.82\n",
      "2018-03-20T06:33:27.295628: step 294, softmax_loss 27.8654, acc 0.86\n",
      "2018-03-20T06:33:27.439648: step 295, softmax_loss 10.9151, acc 0.92\n",
      "2018-03-20T06:33:27.583582: step 296, softmax_loss 19.5086, acc 0.86\n",
      "2018-03-20T06:33:27.729421: step 297, softmax_loss 30.4309, acc 0.84\n",
      "2018-03-20T06:33:27.876772: step 298, softmax_loss 20.0821, acc 0.82\n",
      "2018-03-20T06:33:28.021434: step 299, softmax_loss 21.7424, acc 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-20T06:33:28.162651: step 300, softmax_loss 20.233, acc 0.9\r\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-300\n",
      "2018-03-20T06:33:30.192670: step 301, softmax_loss 25.5118, acc 0.82\n",
      "2018-03-20T06:33:30.337569: step 302, softmax_loss 28.6066, acc 0.82\n",
      "2018-03-20T06:33:30.490752: step 303, softmax_loss 28.8639, acc 0.84\n",
      "2018-03-20T06:33:30.640342: step 304, softmax_loss 22.1247, acc 0.9\n",
      "2018-03-20T06:33:30.786081: step 305, softmax_loss 21.6108, acc 0.92\n",
      "2018-03-20T06:33:30.934743: step 306, softmax_loss 26.1556, acc 0.84\n",
      "2018-03-20T06:33:31.077998: step 307, softmax_loss 28.23, acc 0.82\n",
      "2018-03-20T06:33:31.225760: step 308, softmax_loss 25.432, acc 0.82\n",
      "2018-03-20T06:33:31.372327: step 309, softmax_loss 22.7426, acc 0.88\n",
      "2018-03-20T06:33:31.520541: step 310, softmax_loss 29.9416, acc 0.82\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-310\n",
      "2018-03-20T06:33:33.525400: step 311, softmax_loss 19.7703, acc 0.92\n",
      "2018-03-20T06:33:33.671723: step 312, softmax_loss 28.0706, acc 0.84\n",
      "2018-03-20T06:33:33.815122: step 313, softmax_loss 33.6286, acc 0.82\n",
      "2018-03-20T06:33:33.959573: step 314, softmax_loss 23.184, acc 0.82\n",
      "2018-03-20T06:33:34.101515: step 315, softmax_loss 20.071, acc 0.9\n",
      "2018-03-20T06:33:34.249587: step 316, softmax_loss 19.7908, acc 0.92\n",
      "2018-03-20T06:33:34.393851: step 317, softmax_loss 22.4818, acc 0.9\n",
      "2018-03-20T06:33:34.534852: step 318, softmax_loss 17.8051, acc 0.9\n",
      "2018-03-20T06:33:34.683441: step 319, softmax_loss 30.0407, acc 0.84\n",
      "2018-03-20T06:33:34.826103: step 320, softmax_loss 19.4264, acc 0.88\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-320\n",
      "2018-03-20T06:33:37.135383: step 321, softmax_loss 20.7716, acc 0.86\n",
      "2018-03-20T06:33:37.281023: step 322, softmax_loss 17.0772, acc 0.88\n",
      "2018-03-20T06:33:37.424504: step 323, softmax_loss 27.2802, acc 0.78\n",
      "2018-03-20T06:33:37.572692: step 324, softmax_loss 15.5813, acc 0.9\n",
      "2018-03-20T06:33:37.725615: step 325, softmax_loss 20.6173, acc 0.86\n",
      "2018-03-20T06:33:37.867308: step 326, softmax_loss 28.7661, acc 0.86\n",
      "2018-03-20T06:33:38.013956: step 327, softmax_loss 17.2544, acc 0.92\n",
      "2018-03-20T06:33:38.161637: step 328, softmax_loss 22.974, acc 0.86\n",
      "2018-03-20T06:33:38.303640: step 329, softmax_loss 19.0935, acc 0.88\n",
      "2018-03-20T06:33:38.444514: step 330, softmax_loss 23.1156, acc 0.9\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-330\n",
      "2018-03-20T06:33:40.488974: step 331, softmax_loss 27.2409, acc 0.82\n",
      "2018-03-20T06:33:40.641780: step 332, softmax_loss 23.6688, acc 0.86\n",
      "2018-03-20T06:33:40.791878: step 333, softmax_loss 18.023, acc 0.92\n",
      "2018-03-20T06:33:40.934209: step 334, softmax_loss 15.5636, acc 0.96\n",
      "2018-03-20T06:33:41.080169: step 335, softmax_loss 22.6907, acc 0.84\n",
      "2018-03-20T06:33:41.227455: step 336, softmax_loss 27.602, acc 0.8\n",
      "2018-03-20T06:33:41.372597: step 337, softmax_loss 21.8132, acc 0.84\n",
      "2018-03-20T06:33:41.516389: step 338, softmax_loss 31.0209, acc 0.82\n",
      "2018-03-20T06:33:41.664677: step 339, softmax_loss 20.4585, acc 0.88\n",
      "2018-03-20T06:33:41.811548: step 340, softmax_loss 23.1742, acc 0.9\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-340\n",
      "2018-03-20T06:33:43.850182: step 341, softmax_loss 26.9184, acc 0.86\n",
      "2018-03-20T06:33:43.992495: step 342, softmax_loss 17.2525, acc 0.9\n",
      "2018-03-20T06:33:44.130285: step 343, softmax_loss 14.4286, acc 0.86\n",
      "2018-03-20T06:33:44.275362: step 344, softmax_loss 24.3288, acc 0.8\n",
      "2018-03-20T06:33:44.421815: step 345, softmax_loss 17.4021, acc 0.9\n",
      "2018-03-20T06:33:44.575264: step 346, softmax_loss 21.0093, acc 0.9\n",
      "2018-03-20T06:33:44.720365: step 347, softmax_loss 27.2057, acc 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-20T06:33:44.859370: step 348, softmax_loss 14.5458, acc 0.9\n",
      "2018-03-20T06:33:45.002826: step 349, softmax_loss 23.9188, acc 0.88\n",
      "2018-03-20T06:33:45.147167: step 350, softmax_loss 22.9342, acc 0.86\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-350\n",
      "2018-03-20T06:33:47.199209: step 351, softmax_loss 19.7205, acc 0.88\n",
      "2018-03-20T06:33:47.346793: step 352, softmax_loss 21.4704, acc 0.88\n",
      "2018-03-20T06:33:47.493407: step 353, softmax_loss 13.204, acc 0.92\n",
      "2018-03-20T06:33:47.644752: step 354, softmax_loss 18.8793, acc 0.88\n",
      "2018-03-20T06:33:47.796019: step 355, softmax_loss 24.161, acc 0.84\n",
      "2018-03-20T06:33:47.937907: step 356, softmax_loss 14.6815, acc 0.94\n",
      "2018-03-20T06:33:48.082506: step 357, softmax_loss 19.0466, acc 0.84\n",
      "2018-03-20T06:33:48.230863: step 358, softmax_loss 19.7355, acc 0.86\n",
      "2018-03-20T06:33:48.382971: step 359, softmax_loss 17.9045, acc 0.9\n",
      "2018-03-20T06:33:48.528713: step 360, softmax_loss 18.9466, acc 0.92\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-360\n",
      "2018-03-20T06:33:50.571375: step 361, softmax_loss 26.7545, acc 0.82\n",
      "2018-03-20T06:33:50.719043: step 362, softmax_loss 16.8134, acc 0.92\n",
      "2018-03-20T06:33:50.861141: step 363, softmax_loss 16.3733, acc 0.9\n",
      "2018-03-20T06:33:51.014392: step 364, softmax_loss 23.153, acc 0.84\n",
      "2018-03-20T06:33:51.160173: step 365, softmax_loss 20.538, acc 0.86\n",
      "2018-03-20T06:33:51.305572: step 366, softmax_loss 15.3703, acc 0.9\n",
      "2018-03-20T06:33:51.451590: step 367, softmax_loss 16.16, acc 0.9\n",
      "2018-03-20T06:33:51.601312: step 368, softmax_loss 20.8869, acc 0.86\n",
      "2018-03-20T06:33:51.749112: step 369, softmax_loss 23.9652, acc 0.88\n",
      "2018-03-20T06:33:51.897645: step 370, softmax_loss 12.054, acc 0.94\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-370\n",
      "2018-03-20T06:33:53.918011: step 371, softmax_loss 26.8763, acc 0.76\n",
      "2018-03-20T06:33:54.061065: step 372, softmax_loss 18.6529, acc 0.88\n",
      "2018-03-20T06:33:54.202568: step 373, softmax_loss 23.8903, acc 0.84\n",
      "2018-03-20T06:33:54.349649: step 374, softmax_loss 24.2258, acc 0.84\n",
      "2018-03-20T06:33:54.503386: step 375, softmax_loss 16.9901, acc 0.88\n",
      "2018-03-20T06:33:54.653983: step 376, softmax_loss 19.4158, acc 0.94\n",
      "2018-03-20T06:33:54.802623: step 377, softmax_loss 23.3507, acc 0.84\n",
      "2018-03-20T06:33:54.943728: step 378, softmax_loss 11.9092, acc 0.96\n",
      "2018-03-20T06:33:55.082431: step 379, softmax_loss 23.1907, acc 0.86\n",
      "2018-03-20T06:33:55.224460: step 380, softmax_loss 14.7815, acc 0.94\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-380\n",
      "2018-03-20T06:33:57.290504: step 381, softmax_loss 25.2538, acc 0.84\n",
      "2018-03-20T06:33:57.435133: step 382, softmax_loss 14.2603, acc 0.94\n",
      "2018-03-20T06:33:57.581212: step 383, softmax_loss 18.9063, acc 0.9\n",
      "2018-03-20T06:33:57.729078: step 384, softmax_loss 17.1555, acc 0.88\n",
      "2018-03-20T06:33:57.874605: step 385, softmax_loss 11.544, acc 0.9\n",
      "2018-03-20T06:33:58.020582: step 386, softmax_loss 18.9563, acc 0.88\n",
      "2018-03-20T06:33:58.173547: step 387, softmax_loss 17.4848, acc 0.9\n",
      "2018-03-20T06:33:58.319502: step 388, softmax_loss 12.8048, acc 0.92\n",
      "2018-03-20T06:33:58.464714: step 389, softmax_loss 20.1003, acc 0.9\n",
      "2018-03-20T06:33:58.614442: step 390, softmax_loss 17.0352, acc 0.9\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-390\n",
      "2018-03-20T06:34:00.654005: step 391, softmax_loss 16.0542, acc 0.88\n",
      "2018-03-20T06:34:00.797686: step 392, softmax_loss 18.532, acc 0.9\n",
      "2018-03-20T06:34:00.944600: step 393, softmax_loss 17.4872, acc 0.9\n",
      "2018-03-20T06:34:01.087391: step 394, softmax_loss 9.80788, acc 0.92\n",
      "2018-03-20T06:34:01.235119: step 395, softmax_loss 16.0862, acc 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-20T06:34:01.378137: step 396, softmax_loss 17.2182, acc 0.92\n",
      "2018-03-20T06:34:01.536490: step 397, softmax_loss 14.6918, acc 0.9\n",
      "2018-03-20T06:34:01.690111: step 398, softmax_loss 27.3613, acc 0.82\n",
      "2018-03-20T06:34:01.836767: step 399, softmax_loss 22.8624, acc 0.88\n",
      "2018-03-20T06:34:01.986950: step 400, softmax_loss 19.6288, acc 0.86\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-400\n",
      "2018-03-20T06:34:04.040035: step 401, softmax_loss 24.3307, acc 0.88\n",
      "2018-03-20T06:34:04.192422: step 402, softmax_loss 21.7437, acc 0.84\n",
      "2018-03-20T06:34:04.342801: step 403, softmax_loss 15.0573, acc 0.94\n",
      "2018-03-20T06:34:04.484350: step 404, softmax_loss 21.6695, acc 0.86\n",
      "2018-03-20T06:34:04.635661: step 405, softmax_loss 15.4876, acc 0.92\n",
      "2018-03-20T06:34:04.790131: step 406, softmax_loss 12.0599, acc 0.94\n",
      "2018-03-20T06:34:04.936748: step 407, softmax_loss 14.3668, acc 0.9\n",
      "2018-03-20T06:34:05.082912: step 408, softmax_loss 9.33533, acc 0.96\n",
      "2018-03-20T06:34:05.221394: step 409, softmax_loss 18.7355, acc 0.88\n",
      "2018-03-20T06:34:05.364317: step 410, softmax_loss 17.9869, acc 0.9\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-410\n",
      "2018-03-20T06:34:07.694856: step 411, softmax_loss 9.36196, acc 0.98\n",
      "2018-03-20T06:34:07.845691: step 412, softmax_loss 8.67563, acc 0.96\n",
      "2018-03-20T06:34:08.000921: step 413, softmax_loss 13.2231, acc 0.94\n",
      "2018-03-20T06:34:08.150916: step 414, softmax_loss 11.4965, acc 0.94\n",
      "2018-03-20T06:34:08.297821: step 415, softmax_loss 15.1832, acc 0.9\n",
      "2018-03-20T06:34:08.442781: step 416, softmax_loss 12.6511, acc 0.92\n",
      "2018-03-20T06:34:08.592599: step 417, softmax_loss 17.8762, acc 0.88\n",
      "2018-03-20T06:34:08.743435: step 418, softmax_loss 10.7056, acc 0.96\n",
      "2018-03-20T06:34:08.889380: step 419, softmax_loss 21.2062, acc 0.86\n",
      "2018-03-20T06:34:09.038532: step 420, softmax_loss 7.00856, acc 0.98\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-420\n",
      "2018-03-20T06:34:11.122866: step 421, softmax_loss 12.2596, acc 0.92\n",
      "2018-03-20T06:34:11.271223: step 422, softmax_loss 22.9004, acc 0.88\n",
      "2018-03-20T06:34:11.417740: step 423, softmax_loss 21.9155, acc 0.86\n",
      "2018-03-20T06:34:11.568262: step 424, softmax_loss 11.3827, acc 0.94\n",
      "2018-03-20T06:34:11.716461: step 425, softmax_loss 16.9786, acc 0.88\n",
      "2018-03-20T06:34:11.871379: step 426, softmax_loss 6.72367, acc 0.96\n",
      "2018-03-20T06:34:12.032096: step 427, softmax_loss 21.3278, acc 0.88\n",
      "2018-03-20T06:34:12.176641: step 428, softmax_loss 20.5855, acc 0.84\n",
      "2018-03-20T06:34:12.325973: step 429, softmax_loss 15.729, acc 0.92\n",
      "2018-03-20T06:34:12.472108: step 430, softmax_loss 12.4553, acc 0.94\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-430\n",
      "2018-03-20T06:34:14.529877: step 431, softmax_loss 24.5844, acc 0.84\n",
      "2018-03-20T06:34:14.678542: step 432, softmax_loss 13.7049, acc 0.9\n",
      "2018-03-20T06:34:14.825811: step 433, softmax_loss 20.0493, acc 0.88\n",
      "2018-03-20T06:34:14.970433: step 434, softmax_loss 20.2495, acc 0.86\n",
      "2018-03-20T06:34:15.120227: step 435, softmax_loss 22.9552, acc 0.9\n",
      "2018-03-20T06:34:15.270929: step 436, softmax_loss 10.4784, acc 0.98\n",
      "2018-03-20T06:34:15.421569: step 437, softmax_loss 13.5005, acc 0.94\n",
      "2018-03-20T06:34:15.571443: step 438, softmax_loss 8.36463, acc 0.98\n",
      "2018-03-20T06:34:15.722098: step 439, softmax_loss 11.1605, acc 0.92\n",
      "2018-03-20T06:34:15.867544: step 440, softmax_loss 15.8327, acc 0.88\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-440\n",
      "2018-03-20T06:34:17.936433: step 441, softmax_loss 14.7177, acc 0.92\n",
      "2018-03-20T06:34:18.082581: step 442, softmax_loss 12.1698, acc 0.94\n",
      "2018-03-20T06:34:18.229076: step 443, softmax_loss 15.5267, acc 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-20T06:34:18.376474: step 444, softmax_loss 10.4471, acc 0.96\n",
      "2018-03-20T06:34:18.525210: step 445, softmax_loss 17.9843, acc 0.86\n",
      "2018-03-20T06:34:18.679370: step 446, softmax_loss 13.3072, acc 0.92\n",
      "2018-03-20T06:34:18.832089: step 447, softmax_loss 11.6023, acc 0.92\n",
      "2018-03-20T06:34:18.978261: step 448, softmax_loss 13.7049, acc 0.92\n",
      "2018-03-20T06:34:19.122706: step 449, softmax_loss 19.9904, acc 0.88\n",
      "2018-03-20T06:34:19.279364: step 450, softmax_loss 24.7343, acc 0.84\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-450\n",
      "2018-03-20T06:34:21.325075: step 451, softmax_loss 13.7769, acc 0.94\n",
      "2018-03-20T06:34:21.466617: step 452, softmax_loss 10.2725, acc 0.98\n",
      "2018-03-20T06:34:21.613052: step 453, softmax_loss 6.5059, acc 0.98\n",
      "2018-03-20T06:34:21.759246: step 454, softmax_loss 14.8937, acc 0.9\n",
      "2018-03-20T06:34:21.907531: step 455, softmax_loss 12.2551, acc 0.9\n",
      "2018-03-20T06:34:22.062822: step 456, softmax_loss 9.79806, acc 0.94\n",
      "2018-03-20T06:34:22.211791: step 457, softmax_loss 7.02709, acc 0.98\n",
      "2018-03-20T06:34:22.359085: step 458, softmax_loss 18.1612, acc 0.88\n",
      "2018-03-20T06:34:22.515551: step 459, softmax_loss 11.2103, acc 0.94\n",
      "2018-03-20T06:34:22.664484: step 460, softmax_loss 18.3787, acc 0.86\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-460\n",
      "2018-03-20T06:34:24.711178: step 461, softmax_loss 15.795, acc 0.86\n",
      "2018-03-20T06:34:24.856973: step 462, softmax_loss 15.9553, acc 0.86\n",
      "2018-03-20T06:34:24.999640: step 463, softmax_loss 7.21857, acc 0.98\n",
      "2018-03-20T06:34:25.146386: step 464, softmax_loss 11.975, acc 0.92\n",
      "2018-03-20T06:34:25.291204: step 465, softmax_loss 8.26571, acc 0.96\n",
      "2018-03-20T06:34:25.434413: step 466, softmax_loss 11.33, acc 0.96\n",
      "2018-03-20T06:34:25.587512: step 467, softmax_loss 16.0836, acc 0.92\n",
      "2018-03-20T06:34:25.736726: step 468, softmax_loss 13.7772, acc 0.92\n",
      "2018-03-20T06:34:25.882904: step 469, softmax_loss 10.405, acc 0.94\n",
      "2018-03-20T06:34:26.025709: step 470, softmax_loss 11.5876, acc 0.92\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-470\n",
      "2018-03-20T06:34:28.100094: step 471, softmax_loss 8.68157, acc 0.94\n",
      "2018-03-20T06:34:28.248908: step 472, softmax_loss 13.2287, acc 0.92\n",
      "2018-03-20T06:34:28.390273: step 473, softmax_loss 7.59432, acc 0.98\n",
      "2018-03-20T06:34:28.538514: step 474, softmax_loss 8.14548, acc 0.98\n",
      "2018-03-20T06:34:28.686031: step 475, softmax_loss 10.843, acc 0.94\n",
      "2018-03-20T06:34:28.838076: step 476, softmax_loss 7.76648, acc 0.98\n",
      "2018-03-20T06:34:28.990845: step 477, softmax_loss 9.49805, acc 0.92\n",
      "2018-03-20T06:34:29.138979: step 478, softmax_loss 20.9828, acc 0.88\n",
      "2018-03-20T06:34:29.285096: step 479, softmax_loss 12.5461, acc 0.92\n",
      "2018-03-20T06:34:29.434265: step 480, softmax_loss 16.8907, acc 0.88\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-480\n",
      "2018-03-20T06:34:31.481978: step 481, softmax_loss 11.5122, acc 0.94\n",
      "2018-03-20T06:34:31.629063: step 482, softmax_loss 18.8652, acc 0.9\n",
      "2018-03-20T06:34:31.777276: step 483, softmax_loss 17.8163, acc 0.88\n",
      "2018-03-20T06:34:31.924916: step 484, softmax_loss 10.3186, acc 0.94\n",
      "2018-03-20T06:34:32.068864: step 485, softmax_loss 15.6101, acc 0.88\n",
      "2018-03-20T06:34:32.211904: step 486, softmax_loss 11.0301, acc 0.94\n",
      "2018-03-20T06:34:32.355299: step 487, softmax_loss 15.1977, acc 0.88\n",
      "2018-03-20T06:34:32.501233: step 488, softmax_loss 14.7505, acc 0.92\n",
      "2018-03-20T06:34:32.646561: step 489, softmax_loss 14.9262, acc 0.88\n",
      "2018-03-20T06:34:32.798059: step 490, softmax_loss 17.3911, acc 0.86\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-490\n",
      "2018-03-20T06:34:34.862649: step 491, softmax_loss 8.54116, acc 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-20T06:34:35.006037: step 492, softmax_loss 16.1207, acc 0.9\n",
      "2018-03-20T06:34:35.152635: step 493, softmax_loss 4.88653, acc 1\n",
      "2018-03-20T06:34:35.296958: step 494, softmax_loss 7.44063, acc 0.96\n",
      "2018-03-20T06:34:35.437313: step 495, softmax_loss 13.7748, acc 0.94\n",
      "2018-03-20T06:34:35.589126: step 496, softmax_loss 17.651, acc 0.9\n",
      "2018-03-20T06:34:35.742362: step 497, softmax_loss 13.1337, acc 0.92\n",
      "2018-03-20T06:34:35.892802: step 498, softmax_loss 11.0822, acc 0.94\n",
      "2018-03-20T06:34:36.036945: step 499, softmax_loss 14.83, acc 0.9\n",
      "2018-03-20T06:34:36.180569: step 500, softmax_loss 12.44, acc 0.88\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-500\n",
      "2018-03-20T06:34:38.266782: step 501, softmax_loss 9.28727, acc 0.96\n",
      "2018-03-20T06:34:38.414743: step 502, softmax_loss 19.3901, acc 0.86\n",
      "2018-03-20T06:34:38.565650: step 503, softmax_loss 9.18165, acc 0.94\n",
      "2018-03-20T06:34:38.714499: step 504, softmax_loss 12.0336, acc 0.94\n",
      "2018-03-20T06:34:38.861610: step 505, softmax_loss 10.3954, acc 0.94\n",
      "2018-03-20T06:34:39.017756: step 506, softmax_loss 17.224, acc 0.9\n",
      "2018-03-20T06:34:39.163648: step 507, softmax_loss 17.0718, acc 0.88\n",
      "2018-03-20T06:34:39.313051: step 508, softmax_loss 18.7466, acc 0.86\n",
      "2018-03-20T06:34:39.456070: step 509, softmax_loss 10.1142, acc 0.94\n",
      "2018-03-20T06:34:39.598613: step 510, softmax_loss 9.02432, acc 0.96\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-510\n",
      "2018-03-20T06:34:41.912108: step 511, softmax_loss 13.053, acc 0.92\n",
      "2018-03-20T06:34:42.063240: step 512, softmax_loss 16.8012, acc 0.92\n",
      "2018-03-20T06:34:42.208095: step 513, softmax_loss 15.0453, acc 0.88\n",
      "2018-03-20T06:34:42.348047: step 514, softmax_loss 13.0027, acc 0.88\n",
      "2018-03-20T06:34:42.484709: step 515, softmax_loss 8.50257, acc 0.96\n",
      "2018-03-20T06:34:42.634417: step 516, softmax_loss 11.9251, acc 0.9\n",
      "2018-03-20T06:34:42.781869: step 517, softmax_loss 12.9383, acc 0.92\n",
      "2018-03-20T06:34:42.928937: step 518, softmax_loss 11.3458, acc 0.9\n",
      "2018-03-20T06:34:43.075645: step 519, softmax_loss 12.7424, acc 0.9\n",
      "2018-03-20T06:34:43.216623: step 520, softmax_loss 17.7134, acc 0.86\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-520\n",
      "2018-03-20T06:34:45.299283: step 521, softmax_loss 9.02738, acc 0.94\n",
      "2018-03-20T06:34:45.437694: step 522, softmax_loss 18.5569, acc 0.88\n",
      "2018-03-20T06:34:45.585694: step 523, softmax_loss 9.43345, acc 0.92\n",
      "2018-03-20T06:34:45.735539: step 524, softmax_loss 14.139, acc 0.9\n",
      "2018-03-20T06:34:45.881989: step 525, softmax_loss 18.0843, acc 0.9\n",
      "2018-03-20T06:34:46.025612: step 526, softmax_loss 13.8247, acc 0.92\n",
      "2018-03-20T06:34:46.173694: step 527, softmax_loss 11.7537, acc 0.96\n",
      "2018-03-20T06:34:46.317405: step 528, softmax_loss 10.9036, acc 0.94\n",
      "2018-03-20T06:34:46.459414: step 529, softmax_loss 7.66451, acc 0.98\n",
      "2018-03-20T06:34:46.604598: step 530, softmax_loss 22.0359, acc 0.84\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-530\n",
      "2018-03-20T06:34:48.661845: step 531, softmax_loss 14.7706, acc 0.86\n",
      "2018-03-20T06:34:48.809423: step 532, softmax_loss 6.47018, acc 0.96\n",
      "2018-03-20T06:34:48.957821: step 533, softmax_loss 11.4237, acc 0.94\n",
      "2018-03-20T06:34:49.101933: step 534, softmax_loss 13.0088, acc 0.92\n",
      "2018-03-20T06:34:49.247929: step 535, softmax_loss 11.8578, acc 0.94\n",
      "2018-03-20T06:34:49.393670: step 536, softmax_loss 12.2397, acc 0.88\n",
      "2018-03-20T06:34:49.541812: step 537, softmax_loss 13.0453, acc 0.94\n",
      "2018-03-20T06:34:49.689297: step 538, softmax_loss 13.5238, acc 0.92\n",
      "2018-03-20T06:34:49.841402: step 539, softmax_loss 14.0996, acc 0.88\n",
      "2018-03-20T06:34:49.994873: step 540, softmax_loss 15.284, acc 0.88\n",
      "saving model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have saved model to ./model/ATT_GRU_model-540\n",
      "2018-03-20T06:34:52.047206: step 541, softmax_loss 12.5627, acc 0.94\n",
      "2018-03-20T06:34:52.189626: step 542, softmax_loss 9.62767, acc 0.96\n",
      "2018-03-20T06:34:52.334716: step 543, softmax_loss 12.9135, acc 0.9\n",
      "2018-03-20T06:34:52.482042: step 544, softmax_loss 14.9467, acc 0.9\n",
      "2018-03-20T06:34:52.629719: step 545, softmax_loss 12.0622, acc 0.92\n",
      "2018-03-20T06:34:52.786200: step 546, softmax_loss 17.2093, acc 0.86\n",
      "2018-03-20T06:34:52.935078: step 547, softmax_loss 11.1099, acc 0.94\n",
      "2018-03-20T06:34:53.077189: step 548, softmax_loss 21.3979, acc 0.86\n",
      "2018-03-20T06:34:53.220671: step 549, softmax_loss 12.0832, acc 0.9\n",
      "2018-03-20T06:34:53.364237: step 550, softmax_loss 13.5682, acc 0.92\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-550\n",
      "2018-03-20T06:34:55.427641: step 551, softmax_loss 4.23118, acc 0.98\n",
      "2018-03-20T06:34:55.571270: step 552, softmax_loss 11.1691, acc 0.92\n",
      "2018-03-20T06:34:55.722276: step 553, softmax_loss 8.68909, acc 0.92\n",
      "2018-03-20T06:34:55.868012: step 554, softmax_loss 11.1629, acc 0.9\n",
      "2018-03-20T06:34:56.011051: step 555, softmax_loss 8.51886, acc 0.9\n",
      "2018-03-20T06:34:56.166604: step 556, softmax_loss 12.9651, acc 0.9\n",
      "2018-03-20T06:34:56.315860: step 557, softmax_loss 9.81602, acc 0.96\n",
      "2018-03-20T06:34:56.460554: step 558, softmax_loss 11.7904, acc 0.92\n",
      "2018-03-20T06:34:56.604610: step 559, softmax_loss 7.54205, acc 0.96\n",
      "2018-03-20T06:34:56.752903: step 560, softmax_loss 11.6068, acc 0.94\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-560\n",
      "2018-03-20T06:34:58.809340: step 561, softmax_loss 2.78671, acc 1\n",
      "2018-03-20T06:34:58.953378: step 562, softmax_loss 5.03234, acc 0.98\n",
      "2018-03-20T06:34:59.095793: step 563, softmax_loss 10.8178, acc 0.96\n",
      "2018-03-20T06:34:59.247564: step 564, softmax_loss 13.4907, acc 0.88\n",
      "2018-03-20T06:34:59.397568: step 565, softmax_loss 10.6211, acc 0.92\n",
      "2018-03-20T06:34:59.546446: step 566, softmax_loss 11.0564, acc 0.92\n",
      "2018-03-20T06:34:59.696647: step 567, softmax_loss 8.087, acc 0.94\n",
      "2018-03-20T06:34:59.846481: step 568, softmax_loss 9.00053, acc 0.96\n",
      "2018-03-20T06:34:59.991787: step 569, softmax_loss 6.92573, acc 1\n",
      "2018-03-20T06:35:00.136034: step 570, softmax_loss 4.34292, acc 0.98\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-570\n",
      "2018-03-20T06:35:02.190866: step 571, softmax_loss 9.22335, acc 0.94\n",
      "2018-03-20T06:35:02.335150: step 572, softmax_loss 3.52208, acc 1\n",
      "2018-03-20T06:35:02.479334: step 573, softmax_loss 5.91657, acc 0.98\n",
      "2018-03-20T06:35:02.627537: step 574, softmax_loss 11.8893, acc 0.92\n",
      "2018-03-20T06:35:02.774973: step 575, softmax_loss 5.33828, acc 0.98\n",
      "2018-03-20T06:35:02.921444: step 576, softmax_loss 17.2717, acc 0.86\n",
      "2018-03-20T06:35:03.073264: step 577, softmax_loss 6.96031, acc 0.96\n",
      "2018-03-20T06:35:03.219189: step 578, softmax_loss 5.86234, acc 0.96\n",
      "2018-03-20T06:35:03.363574: step 579, softmax_loss 8.2122, acc 0.98\n",
      "2018-03-20T06:35:03.508015: step 580, softmax_loss 8.79785, acc 0.94\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-580\n",
      "2018-03-20T06:35:05.428380\n"
     ]
    }
   ],
   "source": [
    "!python train_GRU.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "G9pwnCo6HvCk",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 42.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 2791.0
    },
    "outputId": "245218b1-ea2c-4289-89c9-8b48207ed7c7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521528203156E12,
     "user_tz": -480.0,
     "elapsed": 443233.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:tensorflow:From /content/network.py:132: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "210次训练结果\n",
      "准确率0.6909620991253644\n",
      "saving all test result...\n",
      "PR curve area:0.7257646952916393\n",
      "220次训练结果\n",
      "准确率0.673469387755102\n",
      "saving all test result...\n",
      "PR curve area:0.7176369284108141\n",
      "230次训练结果\n",
      "准确率0.6909620991253644\n",
      "saving all test result...\n",
      "PR curve area:0.7592203207377133\n",
      "240次训练结果\n",
      "准确率0.6618075801749271\n",
      "saving all test result...\n",
      "PR curve area:0.735000946466412\n",
      "250次训练结果\n",
      "准确率0.6822157434402333\n",
      "saving all test result...\n",
      "PR curve area:0.7330589847019502\n",
      "260次训练结果\n",
      "准确率0.6967930029154519\n",
      "saving all test result...\n",
      "PR curve area:0.7504989671347804\n",
      "270次训练结果\n",
      "准确率0.7201166180758017\n",
      "saving all test result...\n",
      "PR curve area:0.7758815817282468\n",
      "280次训练结果\n",
      "准确率0.7201166180758017\n",
      "saving all test result...\n",
      "PR curve area:0.7741530947374442\n",
      "290次训练结果\n",
      "准确率0.7259475218658892\n",
      "saving all test result...\n",
      "PR curve area:0.762005321529125\n",
      "300次训练结果\n",
      "准确率0.7055393586005831\n",
      "saving all test result...\n",
      "PR curve area:0.7642590598634432\n",
      "310次训练结果\n",
      "准确率0.7376093294460642\n",
      "saving all test result...\n",
      "PR curve area:0.7880609003539762\n",
      "320次训练结果\n",
      "准确率0.7259475218658892\n",
      "saving all test result...\n",
      "PR curve area:0.78007420087406\n",
      "330次训练结果\n",
      "准确率0.7230320699708455\n",
      "saving all test result...\n",
      "PR curve area:0.7840641059197888\n",
      "340次训练结果\n",
      "准确率0.7405247813411079\n",
      "saving all test result...\n",
      "PR curve area:0.8042188722534949\n",
      "350次训练结果\n",
      "准确率0.717201166180758\n",
      "saving all test result...\n",
      "PR curve area:0.7783736998023363\n",
      "360次训练结果\n",
      "准确率0.7434402332361516\n",
      "saving all test result...\n",
      "PR curve area:0.7986971024589445\n",
      "370次训练结果\n",
      "准确率0.7376093294460642\n",
      "saving all test result...\n",
      "PR curve area:0.8001019945186779\n",
      "380次训练结果\n",
      "准确率0.717201166180758\n",
      "saving all test result...\n",
      "PR curve area:0.774826948927849\n",
      "390次训练结果\n",
      "准确率0.7434402332361516\n",
      "saving all test result...\n",
      "PR curve area:0.7964986977875317\n",
      "400次训练结果\n",
      "准确率0.7288629737609329\n",
      "saving all test result...\n",
      "PR curve area:0.8035398853682285\n",
      "410次训练结果\n",
      "准确率0.7551020408163265\n",
      "saving all test result...\n",
      "PR curve area:0.8178751639495405\n",
      "420次训练结果\n",
      "准确率0.7580174927113703\n",
      "saving all test result...\n",
      "PR curve area:0.820647723166964\n",
      "430次训练结果\n",
      "准确率0.7521865889212828\n",
      "saving all test result...\n",
      "PR curve area:0.8092957779764482\n",
      "440次训练结果\n",
      "准确率0.7346938775510204\n",
      "saving all test result...\n",
      "PR curve area:0.810888506863537\n",
      "450次训练结果\n",
      "准确率0.7405247813411079\n",
      "saving all test result...\n",
      "PR curve area:0.8085784317931893\n",
      "460次训练结果\n",
      "准确率0.7696793002915452\n",
      "saving all test result...\n",
      "PR curve area:0.823953301565303\n",
      "470次训练结果\n",
      "准确率0.7551020408163265\n",
      "saving all test result...\n",
      "PR curve area:0.819367197174591\n",
      "480次训练结果\n",
      "准确率0.7696793002915452\n",
      "saving all test result...\n",
      "PR curve area:0.8110615344138731\n",
      "490次训练结果\n",
      "准确率0.749271137026239\n",
      "saving all test result...\n",
      "PR curve area:0.8328450327364084\n",
      "500次训练结果\n",
      "准确率0.7317784256559767\n",
      "saving all test result...\n",
      "PR curve area:0.8089370895127522\n",
      "510次训练结果\n",
      "准确率0.7434402332361516\n",
      "saving all test result...\n",
      "PR curve area:0.8274804546364102\n",
      "520次训练结果\n",
      "准确率0.7288629737609329\n",
      "saving all test result...\n",
      "PR curve area:0.790722509466689\n",
      "530次训练结果\n",
      "准确率0.7580174927113703\n",
      "saving all test result...\n",
      "PR curve area:0.8234247266516551\n",
      "540次训练结果\n",
      "准确率0.7667638483965015\n",
      "saving all test result...\n",
      "PR curve area:0.8382732748598742\n",
      "550次训练结果\n",
      "准确率0.7784256559766763\n",
      "saving all test result...\n",
      "PR curve area:0.8450250965873349\n",
      "560次训练结果\n",
      "准确率0.7842565597667639\n",
      "saving all test result...\n",
      "PR curve area:0.8420197184562739\n",
      "570次训练结果\n",
      "准确率0.8017492711370262\n",
      "saving all test result...\n",
      "PR curve area:0.8461164427102259\n",
      "580次训练结果\n",
      "准确率0.7696793002915452\n",
      "saving all test result...\n",
      "PR curve area:0.8315947912687632\n"
     ]
    }
   ],
   "source": [
    "!python evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hvAy9vENJ5dZ",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 7.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 102.0
    },
    "outputId": "ece13ade-18f8-4a2f-a93b-277dc37fc03f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521529449569E12,
     "user_tz": -480.0,
     "elapsed": 9798.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into './test2'...\n",
      "remote: Counting objects: 66, done.\u001b[K\n",
      "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
      "remote: Total 66 (delta 20), reused 63 (delta 17), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (66/66), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AlwaysSomeone/RE_11classes.git ./test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MzrbJ3uHM-lG",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 1.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 85.0
    },
    "outputId": "6ff2db32-7a47-4d4c-d2d7-4ff298788c3c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521529459515E12,
     "user_tz": -480.0,
     "elapsed": 3700.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t       model\t    __pycache__      test_GRU.py   train_GRU.py\r\n",
      "datalab        network.py   show_results.py  test_initial  train_loss\r\n",
      "evaluation.py  origin_data  test1\t     test_len.py\r\n",
      "initial.py     out\t    test2\t     time_test.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "lQim8CqcORwt",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "!mv test2/show_results.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZAvZ9hH8OkSw",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 1.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 7007.0
    },
    "outputId": "5e54e111-ae5b-4926-8330-511b2083c6e5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.52152956482E12,
     "user_tz": -480.0,
     "elapsed": 3973.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n",
      "  from ._conv import register_converters as _register_converters\n",
      "甲状腺功能亢进症(简称甲亢)，是由多种原因引起的甲状腺功能亢进和(或)血循环中甲状腺激素水平增高所致的一组常见的内分泌病，临床上以高代谢征群、甲状腺肿大，突眼症、神经及心血管系统功能紊乱为特征，病理上甲状腺可呈弥漫性，结节性或混合性肿大等表现。\n",
      "两实体为：甲亢 和 高代谢征群\n",
      "实际关系为：症状\n",
      "预测关系为：别称\n",
      "\n",
      "\n",
      "黄疸是高胆红素血症的临床表现，即血中胆红素增而使巩膜、皮肤、粘膜以及其他组织和体液发生黄染的现象。\n",
      "两实体为：黄疸 和 高胆红素血症\n",
      "实际关系为：症状\n",
      "预测关系为：检查\n",
      "\n",
      "\n",
      "新生儿呼吸窘迫综合征，也称为肺透明膜病，系指出生后不久即出现进行性呼吸困难、青紫、呼气性呻吟、吸气性三凹征和呼吸衰竭。\n",
      "两实体为：新生儿呼吸窘迫综合征 和 呼吸困难\n",
      "实际关系为：症状\n",
      "预测关系为：人群\n",
      "\n",
      "\n",
      "肝肺综合症临床上以呼吸困难和发绀等低氧血症为突出表现。\n",
      "两实体为：肝肺综合症 和 呼吸困难\n",
      "实际关系为：症状\n",
      "预测关系为：并发症\n",
      "\n",
      "\n",
      "急性铍中毒为短时间吸入高浓度铍及其化合物的烟尘，蒸汽所致，临床表现为化学性支气管炎和肺炎。\n",
      "两实体为：铍中毒 和 化学性支气管炎\n",
      "实际关系为：症状\n",
      "预测关系为：相关疾病\n",
      "\n",
      "\n",
      "乳酸性酸中毒轻者可仅有恶心，腹痛，食欲下降，头昏嗜睡等症状，病情较重的可出现全身酸软，口唇发绀，低血压，昏迷，休克，甚至死亡，因此要积极治疗。\n",
      "两实体为：乳酸性酸中毒 和 昏迷\n",
      "实际关系为：症状\n",
      "预测关系为：别称\n",
      "\n",
      "\n",
      "成人呼吸窘迫综合征简称ARDS，是一种继发的，以急性呼吸窘迫和低氧血症为特征的综合征\n",
      "两实体为：成人呼吸窘迫综合征 和 急性呼吸窘迫\n",
      "实际关系为：症状\n",
      "预测关系为：别称\n",
      "\n",
      "\n",
      "甲状腺功能亢进症(简称甲亢)，是由多种原因引起的甲状腺功能亢进和(或)血循环中甲状腺激素水平增高所致的一组常见的内分泌病，临床上以高代谢征群、甲状腺肿大，突眼症、神经及心血管系统功能紊乱为特征，病理上甲状腺可呈弥漫性，结节性或混合性肿大等表现。\n",
      "两实体为：甲亢 和 甲状腺肿大\n",
      "实际关系为：症状\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "二硫化碳中毒是指因生产中发生事故而吸入二硫化碳高浓度蒸气所致中枢神经系统损害，急性中毒时轻者酒醉状态，步态不稳，感觉异常，重者可出现兴奋，谵妄，严重时发生昏迷、抽搐，甚至呼吸中枢麻痹导致死亡。\n",
      "两实体为：二硫化碳中毒 和 酒醉状态\n",
      "实际关系为：症状\n",
      "预测关系为：相关疾病\n",
      "\n",
      "\n",
      "肺泡蛋白沉着症病因未明，推测与几方面因素有关：如大量粉尘吸入(铝，二氧化硅等)，机体免疫功能下降(尤其婴幼儿)，遗传因素，酗酒，微生物感染等。\n",
      "两实体为：肺泡蛋白沉着症 和 酗酒\n",
      "实际关系为：病因\n",
      "预测关系为：相关疾病\n",
      "\n",
      "\n",
      "肺隐球菌病为新型隐球菌感染引起的亚急性或慢性内脏真菌病，此菌属腐生酵母菌，不形成菌丝和孢子，广泛存在于自然界中\n",
      "两实体为：肺隐球菌病 和 新型隐球菌\n",
      "实际关系为：病因\n",
      "预测关系为：上位词\n",
      "\n",
      "\n",
      "急性心功能不全引起急性心功能不全的原因比较多，其中心瓣膜疾病、冠状动脉硬化、高血压、内分泌疾患、细菌毒素，急性肺梗塞、肺气肿或其他慢性肺脏疾患等均可引起心脏病而产生心力衰竭的表现。\n",
      "两实体为：急性心功能不全 和 心瓣膜疾病\n",
      "实际关系为：病因\n",
      "预测关系为：相关疾病\n",
      "\n",
      "\n",
      "结、直肠黑变病可能与服用蒽醌类泻药有关，而且该病患者中大肠癌和大肠腺瘤性息肉的发生率高，少数患者还可出现假性肠狭窄，而误行剖腹手术。\n",
      "两实体为：结、直肠黑变病 和 泻药\n",
      "实际关系为：病因\n",
      "预测关系为：部位\n",
      "\n",
      "\n",
      "日常所讲的肺炎主要是指细菌性感染引起的肺炎，此肺炎也是最常见的一种，在抗生素应用以前，细菌性肺炎对儿童及老年人健康威胁极大。\n",
      "两实体为：肺炎 和 细菌性感染\n",
      "实际关系为：病因\n",
      "预测关系为：别称\n",
      "\n",
      "\n",
      "哮喘性肺嗜酸粒细胞浸润症近年可以通过检测血清GM试验或血和支气管肺泡盥洗液中曲霉菌特异性IgG、IgM、IgE诊断。\n",
      "两实体为：哮喘性肺嗜酸粒细胞浸润症 和 血清GM试验\n",
      "实际关系为：检查\n",
      "预测关系为：下位词\n",
      "\n",
      "\n",
      "对于非典，胸部X线检查可见肺部炎性浸润影、实验室检查外周血白细胞计数正常或降低，抗菌药物治疗无效是其重要特征\n",
      "两实体为：非典 和 胸部X线\n",
      "实际关系为：检查\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "迁延性肺嗜酸粒细胞浸润症病人，可表现无症状仅有胸部X线异常，也可重至发生呼吸衰竭。\n",
      "两实体为：迁延性肺嗜酸粒细胞浸润症 和 胸部X线\n",
      "实际关系为：检查\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "特发性肺纤维化患者肺组织学和胸部CT特征性表现为普通型间质性肺炎，病因不清\n",
      "两实体为：特发性肺纤维化 和 胸部CT\n",
      "实际关系为：检查\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "冠状动脉终止异常大多数没有明显临床症状，常因体检时发现连续性心脏杂音，心脏轻度增大或肺野充血引起注意而得到诊断。\n",
      "两实体为：冠状动脉终止异常 和 心脏杂音\n",
      "实际关系为：检查\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "左心室双出口心电图检查：常见左心室肥大。\n",
      "两实体为：左心室双出口 和 心电图\n",
      "实际关系为：检查\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "急性腐蚀性胃炎急性期一般不宜作上消化道钡餐检查，以免引起食管和胃穿孔，待急性期过后，钡餐检查可了解胃窦黏膜有无粗乱。\n",
      "两实体为：钡餐 和 胃炎\n",
      "实际关系为：检查\n",
      "预测关系为：别称\n",
      "\n",
      "\n",
      "取直肠炎患者尿道分泌物或宫颈分泌物，涂片检查，作革兰氏染色，在多形核白细胞内找到革兰氏阴性双球菌，涂片对有大量脓性分泌物的单纯淋菌性前尿道炎患者，此法阳性率在90%左右，可以初步诊断。\n",
      "两实体为：直肠炎 和 涂片检查\n",
      "实际关系为：检查\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "横结肠扩张等有助于诊断与排除输尿管结石，肠梗阻等其他可能，但特异性很差。\n",
      "两实体为：横结肠扩张 和 输尿管结石\n",
      "实际关系为：检查\n",
      "预测关系为：部位\n",
      "\n",
      "\n",
      "迁延性肺嗜酸粒细胞浸润症外周血嗜酸粒细胞比例在10%～40%之间，血沉显著增快可达100mm/h。\n",
      "两实体为：迁延性肺嗜酸粒细胞浸润症 和 嗜酸粒细胞比例\n",
      "实际关系为：检查\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "哮喘性肺嗜酸粒细胞浸润症诊断主要根据有肺部浸润改变或伴近端支气管扩张，痰和血中嗜酸粒细胞增多，对烟曲菌等抗原皮试阳性以及血中总IgE升高或出现沉淀抗体。\n",
      "两实体为：哮喘性肺嗜酸粒细胞浸润症 和 嗜酸粒细胞\n",
      "实际关系为：检查\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "但近年来，尽管应用强有力的抗生素和有效的疫苗，肺炎总的病死率不再降低，甚至有所上升\n",
      "两实体为：肺炎 和 疫苗\n",
      "实际关系为：治疗\n",
      "预测关系为：检查\n",
      "\n",
      "\n",
      "适当输液，纠正脱水、碱中毒及休克等。有手足搐搦症时，静脉缓注10%葡萄糖酸钙溶液。早期应用1\n",
      "两实体为：输液 和 休克\n",
      "实际关系为：治疗\n",
      "预测关系为：检查\n",
      "\n",
      "\n",
      "发生于口腔颌面部的血管瘤占全身血管瘤的61%，其中大多数发生于颜面皮肤，皮下组织及口腔粘膜、如舌、唇，口底等组织，少数发生于颌骨内或深部组织。\n",
      "两实体为：血管瘤 和 颜面皮肤\n",
      "实际关系为：部位\n",
      "预测关系为：别称\n",
      "\n",
      "\n",
      "小儿感冒，也叫急性上呼吸道感染，简称“上感”，是小儿最常见的疾病，主要侵犯鼻、鼻咽和咽部。\n",
      "两实体为：小儿感冒 和 咽部\n",
      "实际关系为：部位\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "\"肺放线菌病本菌为正常人口腔、龋齿，扁桃体隐窝中的常存菌,多数由于口腔卫生不良，吸入含有放线菌颗粒的分泌物而发病，也可来自血行播散或腹部病灶的直接蔓延，颈面部和胸腹部病变约占1/5。\"\n",
      "两实体为：肺放线菌病 和 胸腹部\n",
      "实际关系为：部位\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "Ehler-Danlos综合征临床上易受累的组织和器官包括皮肤、关节、心血管系统、胃肠道和眼。\n",
      "两实体为：Ehler-Danlos综合征 和 心血管系统\n",
      "实际关系为：部位\n",
      "预测关系为：上位词\n",
      "\n",
      "\n",
      "心脏粘液瘤是原发于心腔内最多见的一种真性肿瘤，一般认为属良性，有一些复杂的表现和恶性倾向，但也有人认为是恶性程度较低的真性肿瘤，粘液瘤可发生于所有心脏的心内膜面，95%的病例发生于心房，其中大约75%的病例病变位于左心房，20%位于右心房，左、右心室各占2.5%，左心房粘液肿瘤常发生于卵园窝附近，临床上常因瘤体堵塞二尖瓣口，导致二尖瓣口狭窄或关闭不全。\n",
      "两实体为：心脏内粘液瘤 和 心腔\n",
      "实际关系为：部位\n",
      "预测关系为：别称\n",
      "\n",
      "\n",
      "心房扑动与心房颤动是发生于心房内的，冲动频率较房性心动过速更快的心律失常。\n",
      "两实体为：心房颤动 和 心房\n",
      "实际关系为：部位\n",
      "预测关系为：别称\n",
      "\n",
      "\n",
      "炎症易扩散至其他部位，如心包、脑、肝等，引起迁徙性化脓病变。\n",
      "两实体为：炎症 和 心包\n",
      "实际关系为：部位\n",
      "预测关系为：下位词\n",
      "\n",
      "\n",
      "雷诺病一般以上肢较重，偶见于下肢。\n",
      "两实体为：雷诺病 和 下肢\n",
      "实际关系为：部位\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "血栓闭塞性脉管炎病变主要累及四肢远端的中、小动脉，伴行静脉和浅表静脉也常累及，以下肢为主。\n",
      "两实体为：血栓闭塞性脉管炎 和 下肢\n",
      "实际关系为：部位\n",
      "预测关系为：检查\n",
      "\n",
      "\n",
      "先天性动静脉瘘病变可发生于人体任何部位，一般多见于四肢，常累及许多细小动静脉分支，瘘口具多发性，病变常呈弥漫性，瘘口细小时一般无血管搏动和杂音，动脉造影也经常难以观察到瘘口所在，因而在诊断和治疗上均有一定困难。\n",
      "两实体为：先天性动静脉瘘 和 四肢\n",
      "实际关系为：部位\n",
      "预测关系为：别称\n",
      "\n",
      "\n",
      "乙状窦血栓性静脉炎上述症状每日发作1～3次，须与疟疾、伤寒等病鉴别。\n",
      "两实体为：乙状窦血栓性静脉炎 和 伤寒\n",
      "实际关系为：相关疾病\n",
      "预测关系为：部位\n",
      "\n",
      "\n",
      "在减压后短时间内或减压过程中发病者为急性减压病，主要发生于股骨、肱骨和胫骨，缓慢演变的缺血性骨或骨关节损害为减压性骨坏死。\n",
      "两实体为：减压病 和 缺血性骨\n",
      "实际关系为：相关疾病\n",
      "预测关系为：部位\n",
      "\n",
      "\n",
      "肺曲菌病临床上一般将本病分为曲菌球、变态反应性支气管肺曲菌病(ABPA)和侵入性肺曲菌病(IPA)等三种类型。\n",
      "两实体为：肺曲菌病 和 侵入性肺曲菌病(IPA)\n",
      "实际关系为：相关疾病\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "肺气肿按其发病原因肺气肿有如下几种类型：老年性肺气肿，代偿性肺气肿，间质性肺气肿，灶性肺气肿，旁间隔性肺气肿，阻塞性肺气肿。\n",
      "两实体为：肺气肿 和 旁间隔性肺气肿\n",
      "实际关系为：相关疾病\n",
      "预测关系为：部位\n",
      "\n",
      "\n",
      "鼾症容易造成大脑、血液严重缺氧，形成低血氧症，而诱发高血压、脑心病、心肌梗死、心绞痛。\n",
      "两实体为：鼾症 和 脑心病\n",
      "实际关系为：相关疾病\n",
      "预测关系为：人群\n",
      "\n",
      "\n",
      "呼吸衰竭根据动脉血气分析可分为Ⅰ型呼吸衰竭和Ⅱ型呼吸衰竭，根据病程可分为急性呼吸衰竭和慢性呼吸衰竭。\n",
      "两实体为：呼吸衰竭 和 慢性呼吸衰竭\n",
      "实际关系为：相关疾病\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "气管肿瘤晚期病例常有纵隔淋巴结转移或扩散入肺组织，并可直接侵犯食管、喉返神经和喉部。\n",
      "两实体为：气管肿瘤 和 淋巴结转移\n",
      "实际关系为：相关疾病\n",
      "预测关系为：上位词\n",
      "\n",
      "\n",
      "肺气肿按其发病原因肺气肿有如下几种类型：老年性肺气肿，代偿性肺气肿，间质性肺气肿，灶性肺气肿，旁间隔性肺气肿，阻塞性肺气肿。\n",
      "两实体为：肺气肿 和 老年性肺气肿\n",
      "实际关系为：相关疾病\n",
      "预测关系为：并发症\n",
      "\n",
      "\n",
      "中年人和伴有慢性呼吸道疾病或心脏病患者易并发肺炎\n",
      "两实体为：肺炎 和 心脏病患者\n",
      "实际关系为：人群\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "百日咳多见于5岁以下的小儿，幼婴患本病时易有窒息、肺炎，脑病等并发症，病死率高。\n",
      "两实体为：百日咳 和 小儿\n",
      "实际关系为：人群\n",
      "预测关系为：别称\n",
      "\n",
      "\n",
      "腺病毒肺炎是指多由3型和7型腺病毒感染发生的肺部炎症，并多发于6个月～2岁小儿。\n",
      "两实体为：腺病毒肺炎 和 小儿\n",
      "实际关系为：人群\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "呼吸性细支气管相关的间质性肺疾病患者均为吸烟者或曾经吸烟者。\n",
      "两实体为：呼吸性细支气管相关的间质性肺疾病 和 吸烟者\n",
      "实际关系为：人群\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "慢性肺源性心脏病慢性肺心病的患病率存在地区差异，北方高于南方地区，农村高于城市，并随着年龄增高而增加，吸烟者比不吸烟者患病率明显增多，可出现心律失常，右心衰竭，严重的可出现肺性脑病，休克。\n",
      "两实体为：慢性肺源性心脏病 和 吸烟者\n",
      "实际关系为：人群\n",
      "预测关系为：部位\n",
      "\n",
      "\n",
      "吸入性损伤其多发生于大面积，尤其是伴有头面部烧伤患者。\n",
      "两实体为：吸入性损伤 和 头面部烧伤患者\n",
      "实际关系为：人群\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "新生儿窒息是指由于产前、产时或产后的各种病因，使胎儿缺氧而发生呼吸、循环障碍，以低氧血症、高碳酸血症和酸中毒为主要病理生理改变的疾病。\n",
      "两实体为：新生儿窒息 和 胎儿\n",
      "实际关系为：人群\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "羊水与胎粪吸入综合征是指胎儿在宫内或娩出过程中吸入被胎粪污染的羊水，发生气道阻塞、肺内炎症和一系列全身症状，严重者发展成呼吸衰竭或死亡。\n",
      "两实体为：羊水与胎粪吸入综合征 和 胎儿\n",
      "实际关系为：人群\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "大叶性肺炎好发于青壮年男性和冬春季节，常见诱因有受凉、淋雨、醉酒或全身麻醉手术后、镇静剂过量等，当这些诱因使呼吸道防御功能被削弱时，细菌侵入肺泡通过变态反应使肺泡壁毛细血管通透性增强，浆液及纤维素渗出，富含蛋白的渗出物中细菌迅速繁殖，并向邻近肺组织蔓延，波及一个肺段或整个肺叶。\n",
      "两实体为：大叶性肺炎 和 青壮年男性\n",
      "实际关系为：人群\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "支原体肺炎好发于儿童或青少年，约占肺炎总数的10%，在非细菌性肺炎中占三分之一，流行年可高达40%～61%;一般预后良好，为自限性疾病。\n",
      "两实体为：支原体肺炎 和 青少年\n",
      "实际关系为：人群\n",
      "预测关系为：相关疾病\n",
      "\n",
      "\n",
      "大多数儿童及青少年主动脉瓣膜部狭窄病例常无明显症状，仅因发现心脏杂音就医，才明确诊断。\n",
      "两实体为：主动脉瓣膜部狭窄 和 青少年\n",
      "实际关系为：人群\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "球孢子菌病，亦称圣华金热或溪谷热。\n",
      "两实体为：球孢子菌病 和 圣华金热\n",
      "实际关系为：别称\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "\"普通感冒，祖国医学称\"\"伤风\"\"，是由多种病毒引起的一种呼吸道常见病，其中30%-50%是由某种血清型的鼻病毒引起，普通感冒虽多发于初冬，但任何季节，如春天，夏天也可发生，不同季节的感冒的致病病毒并非完全一样。\"\n",
      "两实体为：感冒 和 伤风\n",
      "实际关系为：别称\n",
      "预测关系为：上位词\n",
      "\n",
      "\n",
      "完全性房室传导阻滞，亦称三度房室传导阻滞，是指由于房室传导系统某部分的传导能力异常降低，所有来自心房的激动都不能下传而引起完全性房室分离。\n",
      "两实体为：房室传导阻滞 和 三度房室传导阻滞\n",
      "实际关系为：别称\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "中暑衰竭是重症中暑中的一种，也称为热衰竭，是在热应激情况时因肌体对热环境不适应，所致的过多液体和电解质丢失，而引起的低血容量和电解质失衡。\n",
      "两实体为：中暑衰竭 和 热衰竭\n",
      "实际关系为：别称\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "减压症，简称DCS，俗称潜水夫病或沉箱病，是由于高压环境作业后减压不当，体内原已溶解的气体超过了过饱和界限，在血管内外及组织中形成气泡所致的全身性疾病\n",
      "两实体为：减压病 和 潜水夫病\n",
      "实际关系为：别称\n",
      "预测关系为：相关疾病\n",
      "\n",
      "\n",
      "过早搏动亦称期前收缩，期外收缩，简称早搏。\n",
      "两实体为：过早搏动 和 期前收缩\n",
      "实际关系为：别称\n",
      "预测关系为：检查\n",
      "\n",
      "\n",
      "川崎病，由日本川崎富作首先报告，曾称为皮肤黏膜淋巴结综合症。\n",
      "两实体为：川崎病 和 皮肤黏膜淋巴结综合症\n",
      "实际关系为：别称\n",
      "预测关系为：病因\n",
      "\n",
      "\n",
      "腹膜炎部分病人可并发盆腔脓肿、肠间脓肿和膈下脓肿、髂窝脓肿及粘连性肠梗阻等。\n",
      "两实体为：腹膜炎 和 盆腔脓肿\n",
      "实际关系为：并发症\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "创伤后肺炎也常为肋骨骨折或胸部创伤的并发症。\n",
      "两实体为：肺炎 和 肋骨骨折\n",
      "实际关系为：并发症\n",
      "预测关系为：症状\n",
      "\n",
      "\n",
      "急性化脓性胆管炎疼痛的部位一般在剑突下和(或)右上腹部，为持续性疼痛阵发性加重，可放射至右侧肩背部，如果出现寒战发热则提示有菌血症。\n",
      "两实体为：急性化脓性胆管炎 和 菌血症\n",
      "实际关系为：并发症\n",
      "预测关系为：相关疾病\n",
      "\n",
      "\n",
      "心功能障碍并发症主要是心源性休克心源性休克和急性心功能衰竭。\n",
      "两实体为：心功能障碍 和 急性心功能衰竭\n",
      "实际关系为：并发症\n",
      "预测关系为：相关疾病\n",
      "\n",
      "\n",
      "颈动脉体瘤是一种少见的化学感受器肿瘤，又称为副神经节瘤。\n",
      "两实体为：颈动脉体瘤 和 化学感受器肿瘤\n",
      "实际关系为：上位词\n",
      "预测关系为：病因\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python show_results.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled3.ipynb",
   "version": "0.3.2",
   "views": {},
   "default_view": {},
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
